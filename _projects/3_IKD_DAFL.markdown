---
layout: page
title: IKD on DAFL
description: Iterative Knowledge Distillation on Data Free Learning 
img: /assets/img/dafl_proj.png
---

This project was done in APPCAIR Lab in collaboration with TCS-Research. The project aims to find a iterative method to perform Knowledge Distillation on Data Free Learning. I have come up with a modification to the current loss function for training faster. 

<div class="social">
  <span class="contacticon center">
    <a href="https://www.github.com/Het-Shah/IKD_DAFL" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  </span>
  <div class="col three caption">
    Github Link to the project.
  </div>
</div>